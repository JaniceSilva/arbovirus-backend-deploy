"""
Job de processamento mensal de predi√ß√µes usando deep learning
"""
import os
import sys
import numpy as np
import pandas as pd
from datetime import datetime, date, timedelta
from typing import Dict, List, Optional
import pickle
import json

# Adicionar o diret√≥rio raiz ao path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from flask import Flask
from src.models.user import db
from src.models.climate import ClimateData
from src.models.arbovirus import ArbovirusData
from src.models.prediction import PredictionResult

class PredictionProcessor:
    """Classe respons√°vel pelo processamento de predi√ß√µes de arboviroses"""
    
    def __init__(self, app: Flask = None):
        self.app = app
        self.model_version = "v1.0.0"
        
    def create_app(self):
        """Criar aplica√ß√£o Flask se n√£o fornecida"""
        if not self.app:
            app = Flask(__name__)
            app.config['SQLALCHEMY_DATABASE_URI'] = f"sqlite:///{os.path.join(os.path.dirname(__file__), '..', 'database', 'app.db')}"
            app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
            db.init_app(app)
            return app
        return self.app
    
    def load_historical_data(self, city: str, state: str, days_back: int = 90) -> pd.DataFrame:
        """
        Carregar dados hist√≥ricos para uma cidade espec√≠fica
        
        Args:
            city: Nome da cidade
            state: Estado
            days_back: N√∫mero de dias para voltar no hist√≥rico
            
        Returns:
            DataFrame com dados hist√≥ricos combinados
        """
        app = self.create_app()
        
        with app.app_context():
            end_date = date.today()
            start_date = end_date - timedelta(days=days_back)
            
            # Carregar dados clim√°ticos
            climate_query = ClimateData.query.filter(
                ClimateData.city == city,
                ClimateData.state == state,
                ClimateData.date >= start_date,
                ClimateData.date <= end_date
            ).order_by(ClimateData.date)
            
            climate_data = []
            for record in climate_query.all():
                climate_data.append({
                    'date': record.date,
                    'temperature_avg': float(record.temperature_avg) if record.temperature_avg else 0,
                    'temperature_min': float(record.temperature_min) if record.temperature_min else 0,
                    'temperature_max': float(record.temperature_max) if record.temperature_max else 0,
                    'precipitation': float(record.precipitation) if record.precipitation else 0,
                    'humidity_avg': float(record.humidity_avg) if record.humidity_avg else 0,
                    'wind_speed_avg': float(record.wind_speed_avg) if record.wind_speed_avg else 0
                })
            
            # Carregar dados de arboviroses
            arbovirus_query = ArbovirusData.query.filter(
                ArbovirusData.city == city,
                ArbovirusData.state == state,
                ArbovirusData.date >= start_date,
                ArbovirusData.date <= end_date
            ).order_by(ArbovirusData.date)
            
            arbovirus_data = []
            for record in arbovirus_query.all():
                arbovirus_data.append({
                    'date': record.date,
                    'cases_dengue': record.cases_dengue or 0,
                    'cases_zika': record.cases_zika or 0,
                    'cases_chikungunya': record.cases_chikungunya or 0,
                    'incidence_dengue': float(record.incidence_dengue) if record.incidence_dengue else 0,
                    'incidence_zika': float(record.incidence_zika) if record.incidence_zika else 0,
                    'incidence_chikungunya': float(record.incidence_chikungunya) if record.incidence_chikungunya else 0
                })
            
            # Combinar dados em DataFrame
            climate_df = pd.DataFrame(climate_data)
            arbovirus_df = pd.DataFrame(arbovirus_data)
            
            if not climate_df.empty and not arbovirus_df.empty:
                # Merge por data
                combined_df = pd.merge(climate_df, arbovirus_df, on='date', how='outer')
                combined_df = combined_df.fillna(0)  # Preencher valores ausentes com 0
                combined_df = combined_df.sort_values('date')
                return combined_df
            elif not climate_df.empty:
                # Apenas dados clim√°ticos dispon√≠veis
                climate_df['cases_dengue'] = 0
                climate_df['cases_zika'] = 0
                climate_df['cases_chikungunya'] = 0
                climate_df['incidence_dengue'] = 0
                climate_df['incidence_zika'] = 0
                climate_df['incidence_chikungunya'] = 0
                return climate_df
            else:
                return pd.DataFrame()
    
    def prepare_features(self, df: pd.DataFrame) -> np.ndarray:
        """
        Preparar features para o modelo de machine learning
        
        Args:
            df: DataFrame com dados hist√≥ricos
            
        Returns:
            Array numpy com features preparadas
        """
        if df.empty:
            return np.array([])
        
        # Selecionar features clim√°ticas
        feature_columns = [
            'temperature_avg', 'temperature_min', 'temperature_max',
            'precipitation', 'humidity_avg', 'wind_speed_avg'
        ]
        
        # Adicionar features derivadas
        df['temp_range'] = df['temperature_max'] - df['temperature_min']
        df['temp_humidity_interaction'] = df['temperature_avg'] * df['humidity_avg']
        
        # Adicionar m√©dias m√≥veis (janela de 7 dias)
        for col in ['temperature_avg', 'precipitation', 'humidity_avg']:
            df[f'{col}_ma7'] = df[col].rolling(window=7, min_periods=1).mean()
        
        # Selecionar todas as features
        all_features = feature_columns + [
            'temp_range', 'temp_humidity_interaction',
            'temperature_avg_ma7', 'precipitation_ma7', 'humidity_avg_ma7'
        ]
        
        # Normalizar features (simples min-max scaling)
        features = df[all_features].values
        
        # Aplicar normaliza√ß√£o b√°sica
        features_normalized = np.zeros_like(features)
        for i in range(features.shape[1]):
            col_data = features[:, i]
            if col_data.max() != col_data.min():
                features_normalized[:, i] = (col_data - col_data.min()) / (col_data.max() - col_data.min())
            else:
                features_normalized[:, i] = col_data
        
        return features_normalized
    
    def simple_prediction_model(self, features: np.ndarray, historical_cases: np.ndarray) -> Dict[str, float]:
        """
        Modelo simples de predi√ß√£o baseado em correla√ß√µes e tend√™ncias
        
        Args:
            features: Features clim√°ticas normalizadas
            historical_cases: Casos hist√≥ricos de arboviroses
            
        Returns:
            Dicion√°rio com predi√ß√µes para cada doen√ßa
        """
        if len(features) == 0 or len(historical_cases) == 0:
            return {
                'predicted_cases_dengue': 0.0,
                'predicted_cases_zika': 0.0,
                'predicted_cases_chikungunya': 0.0,
                'confidence_score': 0.5
            }
        
        # Pegar √∫ltimas features (mais recentes)
        recent_features = features[-7:] if len(features) >= 7 else features
        recent_cases = historical_cases[-30:] if len(historical_cases) >= 30 else historical_cases
        
        # Calcular m√©dias das features recentes
        avg_temp = np.mean(recent_features[:, 0]) if recent_features.shape[1] > 0 else 0.5
        avg_humidity = np.mean(recent_features[:, 4]) if recent_features.shape[1] > 4 else 0.5
        avg_precipitation = np.mean(recent_features[:, 3]) if recent_features.shape[1] > 3 else 0.5
        
        # Calcular tend√™ncia dos casos recentes
        if len(recent_cases) > 1:
            case_trend = np.mean(recent_cases[-7:]) if len(recent_cases) >= 7 else np.mean(recent_cases)
        else:
            case_trend = 0
        
        # Modelo simples baseado em correla√ß√µes conhecidas
        # Dengue: favorecida por alta temperatura e umidade
        dengue_factor = (avg_temp * 0.4 + avg_humidity * 0.4 + avg_precipitation * 0.2)
        predicted_dengue = max(0, case_trend * (1 + dengue_factor * 0.5))
        
        # Zika: similar √† dengue, mas menos comum
        zika_factor = dengue_factor * 0.3
        predicted_zika = max(0, case_trend * 0.2 * (1 + zika_factor))
        
        # Chikungunya: tamb√©m similar, mas com padr√µes diferentes
        chikungunya_factor = dengue_factor * 0.4
        predicted_chikungunya = max(0, case_trend * 0.3 * (1 + chikungunya_factor))
        
        # Calcular score de confian√ßa baseado na quantidade de dados
        confidence = min(0.95, 0.5 + (len(recent_cases) / 60) * 0.4)
        
        return {
            'predicted_cases_dengue': float(predicted_dengue),
            'predicted_cases_zika': float(predicted_zika),
            'predicted_cases_chikungunya': float(predicted_chikungunya),
            'confidence_score': float(confidence)
        }
    
    def generate_predictions(self, cities: List[tuple]) -> List[Dict]:
        """
        Gerar predi√ß√µes para as cidades especificadas
        
        Args:
            cities: Lista de tuplas (cidade, estado)
            
        Returns:
            Lista de dicion√°rios com predi√ß√µes
        """
        predictions = []
        prediction_date = date.today() + timedelta(days=30)  # Predi√ß√£o para 30 dias √† frente
        
        for city, state in cities:
            try:
                print(f"üîÆ Gerando predi√ß√£o para {city}-{state}...")
                
                # Carregar dados hist√≥ricos
                historical_data = self.load_historical_data(city, state)
                
                if not historical_data.empty:
                    # Preparar features
                    features = self.prepare_features(historical_data)
                    historical_cases = historical_data['cases_dengue'].values
                    
                    # Gerar predi√ß√£o
                    prediction = self.simple_prediction_model(features, historical_cases)
                    
                    # Criar registro de predi√ß√£o
                    prediction_record = {
                        'prediction_date': prediction_date,
                        'city': city,
                        'state': state,
                        'model_version': self.model_version,
                        **prediction
                    }
                    
                    predictions.append(prediction_record)
                    print(f"‚úÖ Predi√ß√£o gerada para {city}-{state}: {prediction['predicted_cases_dengue']:.1f} casos de dengue")
                    
                else:
                    print(f"‚ö†Ô∏è Dados hist√≥ricos insuficientes para {city}-{state}")
                    
            except Exception as e:
                print(f"‚ùå Erro ao gerar predi√ß√£o para {city}-{state}: {str(e)}")
        
        return predictions
    
    def save_predictions(self, predictions: List[Dict]):
        """Salvar predi√ß√µes no banco de dados"""
        app = self.create_app()
        
        with app.app_context():
            for record in predictions:
                # Verificar se j√° existe predi√ß√£o para a data e cidade
                existing = PredictionResult.query.filter_by(
                    prediction_date=record['prediction_date'],
                    city=record['city'],
                    state=record['state'],
                    model_version=record['model_version']
                ).first()
                
                if not existing:
                    prediction_obj = PredictionResult(**record)
                    db.session.add(prediction_obj)
                else:
                    # Atualizar predi√ß√£o existente
                    for key, value in record.items():
                        if key not in ['prediction_date', 'city', 'state', 'model_version']:
                            setattr(existing, key, value)
            
            db.session.commit()
            print(f"‚úÖ {len(predictions)} predi√ß√µes salvas no banco de dados")
    
    def run_monthly_prediction(self):
        """Executar processamento mensal de predi√ß√µes"""
        print(f"üöÄ Iniciando processamento mensal de predi√ß√µes - {datetime.now()}")
        
        # Cidades principais para predi√ß√£o
        cities = [
            ('S√£o Paulo', 'SP'),
            ('Rio de Janeiro', 'RJ'),
            ('Belo Horizonte', 'MG'),
            ('Salvador', 'BA'),
            ('Fortaleza', 'CE'),
            ('Recife', 'PE'),
            ('Manaus', 'AM'),
            ('Bras√≠lia', 'DF')
        ]
        
        try:
            # Gerar predi√ß√µes
            predictions = self.generate_predictions(cities)
            
            if predictions:
                self.save_predictions(predictions)
            
            print(f"‚úÖ Processamento mensal conclu√≠do com sucesso - {datetime.now()}")
            
        except Exception as e:
            print(f"‚ùå Erro durante o processamento mensal: {str(e)}")
            raise

def main():
    """Fun√ß√£o principal para execu√ß√£o do job"""
    processor = PredictionProcessor()
    processor.run_monthly_prediction()

if __name__ == '__main__':
    main()

